{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    #IN - вектор признаков (1, количество признаков)\n",
    "    #neurons_count - количество нейронов в слое\n",
    "    #learning_rate - кф обучения\n",
    "    def __init__(self, IN, neurons_count, learning_rate = 0.13):\n",
    "        self.learning_rate = learning_rate\n",
    "        #количество строчек - количество признаков\n",
    "        #количество столбцов - количество нейронов\n",
    "        self.w = np.random.rand(IN, neurons_count)\n",
    "        self.b = np.random.rand(1, neurons_count)\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x) * (1. - self.sigmoid(x))\n",
    "    \n",
    "    def forward(self, X_in):\n",
    "        self.x = X_in\n",
    "        #print(X_in.shape)\n",
    "        #print(self.w.shape)\n",
    "        self.X_out = np.dot(X_in, self.w) + self.b        \n",
    "    \n",
    "        return self.sigmoid(self.X_out)\n",
    "        \n",
    "    def backward(self, error):\n",
    "        #print(\"er\", error)\n",
    "        #print(error.shape)\n",
    "        #print(self.sigmoid_derivative(self.X_out).shape)\n",
    "        dx = np.dot(error * self.sigmoid_derivative(self.X_out), self.w.T)\n",
    "        #print(dx.shape)\n",
    "        dw = np.dot(self.x.T, error * self.sigmoid_derivative(self.X_out))\n",
    "        db = error * self.sigmoid_derivative(self.X_out)\n",
    "        #print(\"dw\", dw)\n",
    "        self.w -= self.learning_rate * dw\n",
    "        self.b -= self.learning_rate * db\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse\n",
    "def loss_function(y, y_real):\n",
    "    return ((y - y_real) ** 2).mean()\n",
    "\n",
    "def loss_function_devirative(y, y_real):\n",
    "    return 1/2 * ((y - y_real) ** 2).mean()\n",
    "\n",
    "def err_func(y, y_real):\n",
    "    return (y - y_real) ** 2\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizate inputs\n",
    "def inputs_normalization():\n",
    "    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    return\n",
    "    #слайд 41 1 лекция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_data():\n",
    "    train_data = pd.read_csv('trainReady.csv', header=None)\n",
    "    test_data = pd.read_csv('testReady.csv', header=None)\n",
    "    #print(test_data)\n",
    "    result_train = train_data[18]\n",
    "    result_test = test_data[17]\n",
    "    train_data.drop(columns=[18, 17, 16], inplace=True)\n",
    "    test_data.drop(columns=[17, 16], inplace=True)\n",
    "    train_data = train_data.to_numpy()\n",
    "    test_data = test_data.to_numpy()\n",
    "\n",
    "    train_data = (train_data - train_data.min(axis=0)) / (train_data.max(axis=0) - train_data.min(axis=0) + 0.000000000000000000000000000000000001)\n",
    "    test_data = (test_data - test_data.min(axis=0)) / (test_data.max(axis=0) - test_data.min(axis=0) + 0.000000000000000000000000000000000001)\n",
    "\n",
    "    train = []\n",
    "    for i in range(len(train_data)-1):\n",
    "        if result_train[i] == 0.0:\n",
    "            train.append((np.array([train_data[i]]), np.array([[1., 0., 0., 0., 0., 0.]])))\n",
    "        if result_train[i] == 1.0:\n",
    "            train.append((np.array([train_data[i]]), np.array([[0., 1., 0., 0., 0., 0.]])))\n",
    "        if result_train[i] == 2.0:\n",
    "            train.append((np.array([train_data[i]]), np.array([[0., 0., 1., 0., 0., 0.]])))\n",
    "        if result_train[i] == 3.0:\n",
    "            train.append((np.array([train_data[i]]), np.array([[0., 0., 0., 1., 0., 0.]])))\n",
    "        if result_train[i] == 4.0:\n",
    "            train.append((np.array([train_data[i]]), np.array([[0., 0., 0., 0., 1., 0.]])))\n",
    "        if result_train[i] == 5.0:\n",
    "            train.append((np.array([train_data[i]]), np.array([[0., 0., 0., 0., 0., 1.]])))\n",
    "    \n",
    "    test = []\n",
    "    for i in range(len(test_data)-1):\n",
    "        if result_test[i] == 0.0:\n",
    "            test.append((np.array([test_data[i]]), np.array([[1., 0., 0., 0., 0., 0.]])))\n",
    "        if result_test[i] == 1.0:\n",
    "            test.append((np.array([test_data[i]]), np.array([[0., 1., 0., 0., 0., 0.]])))\n",
    "        if result_test[i] == 2.0:\n",
    "            test.append((np.array([test_data[i]]), np.array([[0., 0., 1., 0., 0., 0.]])))\n",
    "        if result_test[i] == 3.0:\n",
    "            test.append((np.array([test_data[i]]), np.array([[0., 0., 0., 1., 0., 0.]])))\n",
    "        if result_test[i] == 4.0:\n",
    "            test.append((np.array([test_data[i]]), np.array([[0., 0., 0., 0., 1., 0.]])))\n",
    "        if result_test[i] == 5.0:\n",
    "            test.append((np.array([test_data[i]]), np.array([[0., 0., 0., 0., 0., 1.]])))\n",
    "        \n",
    "    return [train, test]\n",
    "#load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size 49\n",
      "error 0.833208305158452\n",
      "0 0.22448979591836735\n",
      "error 0.24085183157588258\n",
      "100 0.22448979591836735\n",
      "error 0.14385361962041393\n",
      "200 0.24489795918367346\n",
      "error 0.14205362597189575\n",
      "300 0.24489795918367346\n",
      "error 0.14197475457656974\n",
      "400 0.24489795918367346\n",
      "error 0.1419014774681132\n",
      "500 0.24489795918367346\n",
      "error 0.139982952181057\n",
      "600 0.2653061224489796\n",
      "error 0.13873929159104736\n",
      "700 0.2857142857142857\n",
      "error 0.10471707526426953\n",
      "800 0.5102040816326531\n",
      "error 0.035381651530911336\n",
      "900 0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "training_dataset = data[0]\n",
    "print(\"size\", len(training_dataset))\n",
    "testing_dataset = data[1]\n",
    "\n",
    "FEATURES_COUNT = 16\n",
    "FIRST_LAYER_NEURONS = 13\n",
    "SECOND_LAYER_NEURONS = 19\n",
    "THIRD_LAYER_NEURONS = 6\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "IN_layer = Layer(FEATURES_COUNT, FIRST_LAYER_NEURONS)\n",
    "H1_layer = Layer(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS)\n",
    "H2_layer = Layer(SECOND_LAYER_NEURONS, THIRD_LAYER_NEURONS)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    right_answer = 0\n",
    "    #print(len(training_dataset))\n",
    "    error = 0\n",
    "    loss_vec = []\n",
    "    for (X_IN, Y_real) in training_dataset:\n",
    "        #print(X_IN)\n",
    "        X_IN = np.nan_to_num(X_IN)\n",
    "        #X_IN = (X_IN - X_IN.min(axis=0)) / (X_IN.max(axis=0) - X_IN.min(axis=0) + 0.000000000000000000000000000000000001)\n",
    "        #print(X_IN)\n",
    "        #print(Y_real)\n",
    "        \n",
    "        #feedforward\n",
    "        X_OUT_IN_layer = IN_layer.forward(X_IN)\n",
    "        X_OUT_H1_layer = H1_layer.forward(X_OUT_IN_layer)\n",
    "        X_OUT_H2_layer = H2_layer.forward(X_OUT_H1_layer)\n",
    "\n",
    "        #Y = softmax(X_OUT_H2_layer)\n",
    "        Y = X_OUT_H2_layer\n",
    "        \n",
    "        #mse\n",
    "        loss = loss_function(Y, Y_real)\n",
    "        loss_vec.append(loss)\n",
    "\n",
    "        error = loss_function_devirative(Y, Y_real)\n",
    "        #error += err_func(Y, Y_real)\n",
    "        #print(\"error\", error)\n",
    "        #print(\"Y:\", Y, \"Y_real:\", Y_real)\n",
    "        if np.argmax(Y) == np.argmax(Y_real):\n",
    "            right_answer += 1\n",
    "        \n",
    "        #print(Y_real - Y)\n",
    "        #backpropagation\n",
    "        H2_error = H2_layer.backward(-(Y_real-Y))\n",
    "        #print(H2_error)\n",
    "\n",
    "        H1_error = H1_layer.backward(H2_error)\n",
    "        #print(H1_error)\n",
    "\n",
    "        IN_layer.backward(H1_error)\n",
    "        \n",
    "    accuracy = right_answer / len(training_dataset)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"error\", np.array(loss_vec).mean())\n",
    "        print(epoch, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: [[0.23535578 0.00320346 0.68898935 0.00078213 0.00284688 0.00352056]] Y_real: [[1. 0. 0. 0. 0. 0.]]\n",
      "Y: [[7.89318366e-03 9.60691484e-01 6.16727675e-03 9.51141274e-04\n",
      "  2.58570889e-03 1.68993890e-03]] Y_real: [[0. 0. 1. 0. 0. 0.]]\n",
      "Y: [[0.002406   0.84070003 0.00877852 0.00475402 0.00234742 0.00182347]] Y_real: [[0. 0. 1. 0. 0. 0.]]\n",
      "Y: [[2.98808735e-05 3.74435991e-03 2.56901228e-01 7.00537718e-01\n",
      "  1.72562607e-03 2.65460653e-03]] Y_real: [[0. 0. 0. 0. 1. 0.]]\n",
      "Y: [[0.00687775 0.95750737 0.00397919 0.00126055 0.00248661 0.00169158]] Y_real: [[0. 0. 1. 0. 0. 0.]]\n",
      "Y: [[0.00231429 0.01676121 0.97401525 0.01779388 0.00280968 0.00349772]] Y_real: [[0. 1. 0. 0. 0. 0.]]\n",
      "Y: [[9.34205993e-01 3.84337635e-02 3.90624383e-02 1.86045603e-05\n",
      "  2.65862347e-03 2.35485255e-03]] Y_real: [[0. 1. 0. 0. 0. 0.]]\n",
      "Y: [[0.00054097 0.43822682 0.00317894 0.03187905 0.00177639 0.00149994]] Y_real: [[0. 0. 1. 0. 0. 0.]]\n",
      "Y: [[0.0120448  0.91246024 0.02870511 0.00097485 0.00274013 0.00203695]] Y_real: [[1. 0. 0. 0. 0. 0.]]\n",
      "test error 0.1348078361244846\n",
      "dataset len 19\n",
      "right answers 10\n",
      "accuracy 0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "loss_vec = []\n",
    "right_answers = 0\n",
    "for (X_IN, Y_real) in testing_dataset:\n",
    "    X_IN = np.nan_to_num(X_IN)\n",
    "    \n",
    "    #feedforward\n",
    "    X_OUT_IN_layer = IN_layer.forward(X_IN)\n",
    "    X_OUT_H1_layer = H1_layer.forward(X_OUT_IN_layer)\n",
    "    X_OUT_H2_layer = H2_layer.forward(X_OUT_H1_layer)\n",
    "    Y = X_OUT_H2_layer\n",
    "    loss = loss_function(Y, Y_real)\n",
    "    loss_vec.append(loss)\n",
    "        \n",
    "    if np.argmax(Y) == np.argmax(Y_real):\n",
    "            right_answers += 1\n",
    "    else:\n",
    "        print(\"Y:\", Y, \"Y_real:\", Y_real)\n",
    "        \n",
    "    \n",
    "print(\"test error\", np.array(loss_vec).mean())\n",
    "print(\"dataset len\", len(testing_dataset))\n",
    "print(\"right answers\", right_answers)\n",
    "print(\"accuracy\", right_answers/len(testing_dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2]])\n",
    "b = np.array([[1,1]])\n",
    "print(a*b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
