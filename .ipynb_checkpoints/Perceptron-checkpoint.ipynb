{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-cf42261b0a85>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-cf42261b0a85>\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Fi - unlinear \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#derivative Fi\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "    \n",
    "#Loss function\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "\n",
    "def train(X, y_true, learning_rate, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "                \n",
    "        IN_X = np.array()\n",
    "        \n",
    "        W1 = np.array()\n",
    "        b1 = np.array()\n",
    "        W2 = np.array()\n",
    "        b2 = np.array()\n",
    "        W_out = np.array()\n",
    "        b_out = np.array()\n",
    "        \n",
    "        #feedforward\n",
    "        H1 = sigmoid(np.dot(W1, IN_X) + b1)\n",
    "        H2 = sigmoid(np.dot(W2, H1) + b2)\n",
    "        OUT = sigmoid(np.dot(W_out, H2) + b_out)\n",
    "        \n",
    "        #calculate error\n",
    "        error = mse_loss(y_true, y_pred)\n",
    "        \n",
    "        #calculate accuracy \n",
    "        \n",
    "        #backprop\n",
    "        adjustment = dot(training_set_inputs.T, error * sigmoid_derivative(y_pred))\n",
    "        \n",
    "        \n",
    "        w1 -= learning_rate * \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    #IN - вектор признаков (1, количество признаков)\n",
    "    #neurons_count - количество нейронов в слое\n",
    "    #learning_rate - кф обучения\n",
    "    def __init__(self, IN, neurons_count, learning_rate = 0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        #количество строчек - количество признаков\n",
    "        #количество столбцов - количество нейронов\n",
    "        self.w = np.random.rand(IN, neurons_count)\n",
    "        self.b = np.random.rand(1, neurons_count)\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    def forward(self, X_in):\n",
    "        self.x = X_in\n",
    "        print(X_in.shape)\n",
    "        print(self.w.shape)\n",
    "        self.X_out = np.dot(X_in, self.w) + self.b        \n",
    "    \n",
    "        return self.sigmoid(self.X_out)\n",
    "        \n",
    "    def backward(self, error):\n",
    "        print(error.shape)\n",
    "        print(self.sigmoid_derivative(self.X_out).shape)\n",
    "        print()\n",
    "        dx = np.dot(error * self.sigmoid_derivative(self.X_out), self.w.T)\n",
    "        print(dx.shape)\n",
    "        dw = np.dot(self.x.T, error * self.sigmoid_derivative(self.X_out))\n",
    "        db = error * self.sigmoid_derivative(self.X_out)\n",
    "        self.w -= learning_rate * dw\n",
    "        self.b -= learning_rate * db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse\n",
    "def loss_function(y, y_real):\n",
    "    return ((y - y_real) ** 2).mean()\n",
    "\n",
    "def loss_function_devirative(y, y_real):\n",
    "    return 1/2 * (y - y_real) ** 2\n",
    "\n",
    "def err_func(y, y_real):\n",
    "    return (y - y_real) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizate inputs\n",
    "def inputs_normalization():\n",
    "    return\n",
    "    #слайд 41 1 лекция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X=np.array([[1., 2., 3.]])\n",
    "    Y=np.array([[0., 1.]])\n",
    "    traning = np.array([(X, Y)])\n",
    "    test = np.array([([1., 2., 3.], [0., 1.])])\n",
    "    return np.array([traning, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-0505dd0ea21a>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  traning = np.array([(X, Y)])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-63772384c92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mH2_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSECOND_LAYER_NEURONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHIRD_LAYER_NEURONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtraining_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-0505dd0ea21a>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtraning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,) into shape (1,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_IN = np.array([[1., 2., 3.]])\n",
    "Y_real = np.array([[1., 0.]])\n",
    "\n",
    "FEATURES_COUNT = X_IN.shape[1]\n",
    "FIRST_LAYER_NEURONS = 3\n",
    "SECOND_LAYER_NEURONS = 4\n",
    "THIRD_LAYER_NEURONS = 2\n",
    "\n",
    "EPOCHS = 300\n",
    "\n",
    "IN_layer = Layer(FEATURES_COUNT, FIRST_LAYER_NEURONS)\n",
    "H1_layer = Layer(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS)\n",
    "H2_layer = Layer(SECOND_LAYER_NEURONS, THIRD_LAYER_NEURONS)\n",
    "\n",
    "data = load_data()\n",
    "training_dataset = data[0]\n",
    "print(\"size\", training_dataset.size)\n",
    "testing_dataset = data[1]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    right_answer = 0\n",
    "    print(training_dataset.size)\n",
    "    for (X_IN, Y_real) in training_dataset:\n",
    "        X_IN = np.array([X_IN])\n",
    "        Y_real = np.array(Y_real)\n",
    "        #feedforward\n",
    "        X_OUT_IN_layer = IN_layer.forward(X_IN)\n",
    "        X_OUT_H1_layer = H1_layer.forward(X_OUT_IN_layer)\n",
    "        X_OUT_H2_layer = H2_layer.forward(X_OUT_H1_layer)\n",
    "\n",
    "        Y = X_OUT_H2_layer\n",
    "\n",
    "        #mse\n",
    "        loss = loss_function(Y, Y_real)\n",
    "\n",
    "        #error = loss_function_devirative(Y, Y_real)\n",
    "        error = err_func(Y, Y_real)\n",
    "        print(error)\n",
    "        print(\"Y:\", Y, \"Y_real:\", Y_real)\n",
    "        if np.argmax(Y) == np.argmax(Y_real):\n",
    "            right_answer += 1\n",
    "        \n",
    "        #backpropagation\n",
    "        H2_error = H2_layer.backward(error)\n",
    "        print(H2_error)\n",
    "\n",
    "        H1_error = H1_layer.backward(H2_error)\n",
    "        print(H1_error)\n",
    "\n",
    "        IN_layer.backward(H1_error)\n",
    "    \n",
    "    accuracy = right_answer / training_dataset.size\n",
    "    print(epoch, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2]])\n",
    "b = np.array([[1,1]])\n",
    "print(a*b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
