{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-cf42261b0a85>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-cf42261b0a85>\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Fi - unlinear \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#derivative Fi\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "    \n",
    "#Loss function\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "\n",
    "def train(X, y_true, learning_rate, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "                \n",
    "        IN_X = np.array()\n",
    "        \n",
    "        W1 = np.array()\n",
    "        b1 = np.array()\n",
    "        W2 = np.array()\n",
    "        b2 = np.array()\n",
    "        W_out = np.array()\n",
    "        b_out = np.array()\n",
    "        \n",
    "        #feedforward\n",
    "        H1 = sigmoid(np.dot(W1, IN_X) + b1)\n",
    "        H2 = sigmoid(np.dot(W2, H1) + b2)\n",
    "        OUT = sigmoid(np.dot(W_out, H2) + b_out)\n",
    "        \n",
    "        #calculate error\n",
    "        error = mse_loss(y_true, y_pred)\n",
    "        \n",
    "        #calculate accuracy \n",
    "        \n",
    "        #backprop\n",
    "        adjustment = dot(training_set_inputs.T, error * sigmoid_derivative(y_pred))\n",
    "        \n",
    "        \n",
    "        w1 -= learning_rate * \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    #IN - вектор признаков (1, количество признаков)\n",
    "    #neurons_count - количество нейронов в слое\n",
    "    #learning_rate - кф обучения\n",
    "    def __init__(self, IN, neurons_count, learning_rate = 0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        #количество строчек - количество признаков\n",
    "        #количество столбцов - количество нейронов\n",
    "        self.w = np.random.rand(IN, neurons_count)\n",
    "        self.b = np.random.rand(1, neurons_count)\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, ):\n",
    "    \n",
    "    def forward(self, X_in):\n",
    "        self.x = X_in\n",
    "        #print(X_in.shape)\n",
    "        #print(self.w.shape)\n",
    "        X_out = np.dot(X_in, self.w) + self.b        \n",
    "    \n",
    "        return self.sigmoid(X_out)\n",
    "        \n",
    "    def backward(self, error):\n",
    "        \n",
    "        dx = np.dot(self.w.T, error.T * self.sigmoid_derivative(self.x))\n",
    "        dw = np.dot(self.x.T, error.T * self.sigmoid_derivative(self.x))\n",
    "        self.w += learning_rate * dw\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse\n",
    "def loss_function(y, y_real):\n",
    "    return ((y - y_real) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizate inputs\n",
    "def inputs_normalization():\n",
    "    #слайд 41 1 лекция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 3)\n",
      "(1, 3)\n",
      "(3, 4)\n",
      "(1, 4)\n",
      "(4, 2)\n",
      "0.37546597998179404\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_IN = np.array([[1., 2., 3.]])\n",
    "Y_real = np.array([[1., 0.]])\n",
    "\n",
    "FEATURES_COUNT = X_IN.shape[1]\n",
    "FIRST_LAYER_NEURONS = 3\n",
    "SECOND_LAYER_NEURONS = 4\n",
    "THIRD_LAYER_NEURONS = 2\n",
    "\n",
    "IN_layer = Layer(FEATURES_COUNT, FIRST_LAYER_NEURONS)\n",
    "H1_layer = Layer(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS)\n",
    "H2_layer = Layer(SECOND_LAYER_NEURONS, THIRD_LAYER_NEURONS)\n",
    "\n",
    "X_OUT_IN_layer = IN_layer.forward(X_IN)\n",
    "X_OUT_H1_layer = H1_layer.forward(X_OUT_IN_layer)\n",
    "X_OUT_H2_layer = H2_layer.forward(X_OUT_H1_layer)\n",
    "\n",
    "Y = X_OUT_H2_layer\n",
    "\n",
    "#mse\n",
    "error = loss_function(Y, Y_real)\n",
    "print(error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .1\n",
    "epochs = 1000\n",
    "\n",
    "X, y_real = load_dataset()\n",
    "\n",
    "train(X, y_real, learning_rate, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
